model_params:
  name:                   'end_to_end'
  in_channels:            3
  input_dim:              128
  extra_dim:              6
  enable_extra:           False

train_params:
  batch_size:             128
  n_epochs:               150
  optimizer:
    type:                 'Adam'
    learning_rate:        0.00001
    betas:                (0.9, 0.999)
    weight_decay:         0.0
  manual_seed:            1234
  lr_scheduler:
    enable:               False
    step_size:            50
    gamma:                0.5
    
log_params:
  name:                   'end_to_end'
  log_interval:           10
  checkpoint_preload:     True
  use_tensorboard:        True